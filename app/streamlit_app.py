import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import joblib
from io import BytesIO

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Predicci√≥n de Rendimiento de Autos",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo principal
st.markdown('<h1 class="main-header">üöó Sistema de Predicci√≥n de Rendimiento de Autom√≥viles</h1>', 
            unsafe_allow_html=True)
st.markdown("---")

# Sidebar para navegaci√≥n
st.sidebar.title("üìã Navegaci√≥n")
page = st.sidebar.radio(
    "Seleccione una opci√≥n:",
    ["üè† Inicio", "üìä Exploraci√≥n de Datos", "üîß Preprocesamiento", 
     "ü§ñ Entrenamiento", "üìà Evaluaci√≥n", "üéØ Predicciones"]
)

# Estado de sesi√≥n para mantener datos
if 'data' not in st.session_state:
    st.session_state.data = None
if 'model' not in st.session_state:
    st.session_state.model = None
if 'X_train' not in st.session_state:
    st.session_state.X_train = None
if 'X_test' not in st.session_state:
    st.session_state.X_test = None
if 'y_train' not in st.session_state:
    st.session_state.y_train = None
if 'y_test' not in st.session_state:
    st.session_state.y_test = None
if 'preprocessed' not in st.session_state:
    st.session_state.preprocessed = False
if 'X_processed' not in st.session_state:
    st.session_state.X_processed = None
if 'y_processed' not in st.session_state:
    st.session_state.y_processed = None


# ============== P√ÅGINA: INICIO ==============
if page == "üè† Inicio":
    st.header("Bienvenido al Sistema de Machine Learning")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### üìñ Sobre este Proyecto
        
        Esta aplicaci√≥n implementa un **modelo de √Årbol de Regresi√≥n CART** para predecir 
        el rendimiento de autom√≥viles bas√°ndose en sus caracter√≠sticas t√©cnicas.
        
        #### üéØ Objetivos:
        - Aplicar aprendizaje autom√°tico supervisado a un problema real
        - Implementar soluciones usando Programaci√≥n Orientada a Objetos
        - Realizar an√°lisis exploratorio y preprocesamiento de datos
        - Evaluar modelos con m√©tricas apropiadas
        
        #### üîß Tecnolog√≠as Utilizadas:
        - **Python 3.8+**
        - **Scikit-learn**: Modelos de ML
        - **Pandas & NumPy**: Manipulaci√≥n de datos
        - **Matplotlib & Seaborn**: Visualizaciones
        - **Streamlit**: Interfaz web interactiva
        """)
    
    with col2:
        st.info("üìö **Algoritmo Seleccionado**\n\n**√Årboles de Regresi√≥n CART**")
        st.markdown("""
        **¬øPor qu√© CART?**
        - Maneja datos mixtos (num√©ricos/categ√≥ricos)
        - Interpretable y visual
        - No requiere escalado de datos
        - Robusto ante outliers
        - Captura relaciones no lineales
        """)
    
    st.markdown("---")
    
    # Cargar datos
    st.subheader("üìÅ Cargar Dataset")
    
    uploaded_file = st.file_uploader(
        "Sube tu archivo CSV",
        type=['csv'],
        help="El archivo debe contener los datos de rendimiento de autom√≥viles"
    )
    
    if uploaded_file is not None:
        try:
            st.session_state.data = pd.read_csv(uploaded_file)
            st.success(f"‚úÖ Archivo cargado exitosamente: {st.session_state.data.shape[0]} filas, {st.session_state.data.shape[1]} columnas")
            
            with st.expander("üëÄ Vista previa de los datos"):
                st.dataframe(st.session_state.data.head(10))
                
        except Exception as e:
            st.error(f"‚ùå Error al cargar el archivo: {str(e)}")


# ============== P√ÅGINA: EXPLORACI√ìN DE DATOS ==============
elif page == "üìä Exploraci√≥n de Datos":
    st.header("üìä An√°lisis Exploratorio de Datos")
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Por favor, cargue primero un dataset en la p√°gina de Inicio")
    else:
        data = st.session_state.data
        
        # Informaci√≥n general
        st.subheader("üìã Informaci√≥n General del Dataset")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Filas", data.shape[0])
        with col2:
            st.metric("Columnas", data.shape[1])
        with col3:
            st.metric("Valores Faltantes", data.isna().sum().sum())
        with col4:
            st.metric("Duplicados", data.duplicated().sum())
        
        st.markdown("---")
        
        # Estad√≠sticas descriptivas
        st.subheader("üìà Estad√≠sticas Descriptivas")
        st.dataframe(data.describe())
        
        st.markdown("---")
        
        # Valores faltantes
        st.subheader("üîç An√°lisis de Valores Faltantes")
        missing = data.isna().sum()
        missing_pct = (missing / len(data)) * 100
        missing_df = pd.DataFrame({
            'Valores Faltantes': missing,
            'Porcentaje (%)': missing_pct
        }).sort_values('Valores Faltantes', ascending=False)
        
        if missing_df['Valores Faltantes'].sum() > 0:
            fig, ax = plt.subplots(figsize=(10, 6))
            missing_df[missing_df['Valores Faltantes'] > 0]['Porcentaje (%)'].plot(
                kind='bar', ax=ax, color='salmon'
            )
            ax.set_title('Porcentaje de Valores Faltantes por Columna', fontsize=14, fontweight='bold')
            ax.set_ylabel('Porcentaje (%)')
            ax.set_xlabel('Columnas')
            plt.xticks(rotation=45)
            st.pyplot(fig)
        else:
            st.success("‚úÖ No hay valores faltantes en el dataset")
        
        st.markdown("---")
        
        # Distribuciones
        st.subheader("üìä Distribuci√≥n de Variables")
        
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        selected_col = st.selectbox("Seleccione una variable para visualizar:", numeric_cols)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig, ax = plt.subplots(figsize=(8, 5))
            data[selected_col].hist(bins=30, ax=ax, edgecolor='black', alpha=0.7)
            ax.set_title(f'Histograma de {selected_col}', fontsize=12, fontweight='bold')
            ax.set_xlabel(selected_col)
            ax.set_ylabel('Frecuencia')
            ax.grid(alpha=0.3)
            st.pyplot(fig)
        
        with col2:
            fig, ax = plt.subplots(figsize=(8, 5))
            data.boxplot(column=selected_col, ax=ax)
            ax.set_title(f'Boxplot de {selected_col}', fontsize=12, fontweight='bold')
            ax.set_ylabel(selected_col)
            ax.grid(alpha=0.3)
            st.pyplot(fig)
        
        st.markdown("---")
        
        # Matriz de correlaci√≥n
        st.subheader("üîó Matriz de Correlaci√≥n")
        
        if len(numeric_cols) > 1:
            corr_matrix = data[numeric_cols].corr()
            
            fig, ax = plt.subplots(figsize=(12, 8))
            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
                       center=0, ax=ax, cbar_kws={'label': 'Correlaci√≥n'})
            ax.set_title('Matriz de Correlaci√≥n', fontsize=14, fontweight='bold')
            st.pyplot(fig)
            
            # Correlaciones m√°s fuertes con la variable objetivo
            if 'y' in data.columns:
                st.markdown("#### üéØ Correlaciones con la Variable Objetivo (y)")
                target_corr = corr_matrix['y'].drop('y').sort_values(ascending=False)
                
                fig, ax = plt.subplots(figsize=(10, 6))
                target_corr.plot(kind='barh', ax=ax, color='steelblue')
                ax.set_title('Correlaci√≥n con Variable Objetivo', fontsize=12, fontweight='bold')
                ax.set_xlabel('Coeficiente de Correlaci√≥n')
                ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
                ax.grid(alpha=0.3)
                st.pyplot(fig)


# ============== P√ÅGINA: PREPROCESAMIENTO ==============
elif page == "üîß Preprocesamiento":
    st.header("üîß Preprocesamiento de Datos")
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Por favor, cargue primero un dataset en la p√°gina de Inicio")
    else:
        data = st.session_state.data.copy()
        
        st.subheader("1Ô∏è‚É£ Manejo de Valores Faltantes")
        
        # Detectar columnas con valores faltantes
        missing_cols = data.columns[data.isna().any()].tolist()
        
        if missing_cols:
            st.warning(f"Se detectaron valores faltantes en: {', '.join(missing_cols)}")
            
            missing_strategy = {}
            for col in missing_cols:
                strategy = st.selectbox(
                    f"Estrategia para '{col}':",
                    ['mean', 'median', 'mode', 'drop'],
                    key=f"missing_{col}"
                )
                missing_strategy[col] = strategy
            
            if st.button("Aplicar Manejo de Valores Faltantes"):
                for col, strategy in missing_strategy.items():
                    if strategy == 'mean':
                        data[col].fillna(data[col].mean(), inplace=True)
                    elif strategy == 'median':
                        data[col].fillna(data[col].median(), inplace=True)
                    elif strategy == 'mode':
                        data[col].fillna(data[col].mode()[0], inplace=True)
                    elif strategy == 'drop':
                        data.dropna(subset=[col], inplace=True)
                
                st.success("‚úÖ Valores faltantes manejados correctamente")
        else:
            st.success("‚úÖ No hay valores faltantes en el dataset")
        
        st.markdown("---")
        
        st.subheader("2Ô∏è‚É£ Selecci√≥n de Columnas")
        
        all_cols = data.columns.tolist()
        cols_to_drop = st.multiselect(
            "Seleccione columnas a eliminar:",
            all_cols,
            default=[col for col in ['Automovil', 'x4', 'x5'] if col in all_cols],
            help="Columnas que no ser√°n usadas en el modelo"
        )
        
        st.markdown("---")
        
        st.subheader("3Ô∏è‚É£ Codificaci√≥n de Variables Categ√≥ricas")
        
        categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
        
        if categorical_cols:
            cols_to_encode = st.multiselect(
                "Seleccione columnas categ√≥ricas a codificar:",
                categorical_cols,
                default=categorical_cols
            )
        else:
            cols_to_encode = []
            st.info("No se detectaron variables categ√≥ricas")
        
        st.markdown("---")
        
        st.subheader("4Ô∏è‚É£ Variable Objetivo")
        
        target_col = st.selectbox(
            "Seleccione la variable objetivo (target):",
            [col for col in data.columns if col not in cols_to_drop],
            index=[col for col in data.columns if col not in cols_to_drop].index('y') if 'y' in data.columns else 0
        )
        
        st.markdown("---")
        
        if st.button("üöÄ Aplicar Preprocesamiento", type="primary"):
            try:
                # Eliminar columnas seleccionadas
                data = data.drop(cols_to_drop, axis=1)
                
                # Separar X e y
                y = data[target_col]
                X = data.drop(target_col, axis=1)
                
                # Codificar variables categ√≥ricas
                for col in cols_to_encode:
                    if col in X.columns:
                        dummies = pd.get_dummies(X[col], prefix=col, drop_first=True, dtype='int')
                        X = X.drop(col, axis=1)
                        X = pd.concat([X, dummies], axis=1)
                
                # Guardar en session_state
                st.session_state.X_processed = X
                st.session_state.y_processed = y
                st.session_state.preprocessed = True
                
                st.success("‚úÖ Preprocesamiento completado exitosamente")
                
                st.markdown("#### üìä Datos Procesados:")
                st.write(f"**Caracter√≠sticas (X):** {X.shape}")
                st.write(f"**Objetivo (y):** {y.shape}")
                st.dataframe(X.head())
                
            except Exception as e:
                st.error(f"‚ùå Error durante el preprocesamiento: {str(e)}")


# ============== P√ÅGINA: ENTRENAMIENTO ==============
elif page == "ü§ñ Entrenamiento":
    st.header("ü§ñ Entrenamiento del Modelo")
    
    if not st.session_state.preprocessed:
        st.warning("‚ö†Ô∏è Por favor, complete primero el preprocesamiento de datos")
    else:
        X = st.session_state.X_processed
        y = st.session_state.y_processed
        
        st.subheader("‚öôÔ∏è Configuraci√≥n del Modelo")
        
        col1, col2 = st.columns(2)
        
        with col1:
            test_size = st.slider("Tama√±o del conjunto de prueba:", 0.1, 0.4, 0.2, 0.05)
            random_state = st.number_input("Random State:", 0, 100, 42)
        
        with col2:
            max_depth = st.slider("Profundidad m√°xima del √°rbol:", 1, 20, 5)
            min_samples_split = st.slider("M√≠nimo de muestras para dividir:", 2, 50, 10)
            min_samples_leaf = st.slider("M√≠nimo de muestras en hoja:", 1, 20, 5)
        
        st.markdown("---")
        
        # Opci√≥n de b√∫squeda de hiperpar√°metros
        use_grid_search = st.checkbox("üîç Usar b√∫squeda de hiperpar√°metros (GridSearchCV)")
        
        if use_grid_search:
            st.info("‚è≥ La b√∫squeda de hiperpar√°metros puede tardar varios minutos")
        
        st.markdown("---")
        
        if st.button("üéØ Entrenar Modelo", type="primary"):
            with st.spinner("Entrenando modelo..."):
                # Dividir datos
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=int(random_state)
                )
                
                if use_grid_search:
                    # Grid Search
                    param_grid = {
                        'max_depth': [3, 4, 5, 6, 7],
                        'min_samples_split': [5, 10, 15, 20],
                        'min_samples_leaf': [2, 5, 10]
                    }
                    
                    grid_search = GridSearchCV(
                        DecisionTreeRegressor(random_state=int(random_state)),
                        param_grid,
                        cv=5,
                        scoring='r2',
                        n_jobs=-1
                    )
                    
                    grid_search.fit(X_train, y_train)
                    model = grid_search.best_estimator_
                    
                    st.success("‚úÖ B√∫squeda de hiperpar√°metros completada")
                    st.markdown("#### üèÜ Mejores Par√°metros:")
                    st.json(grid_search.best_params_)
                    
                else:
                    # Entrenamiento normal
                    model = DecisionTreeRegressor(
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        min_samples_leaf=min_samples_leaf,
                        random_state=int(random_state)
                    )
                    model.fit(X_train, y_train)
                
                # Guardar en session_state
                st.session_state.model = model
                st.session_state.X_train = X_train
                st.session_state.X_test = X_test
                st.session_state.y_train = y_train
                st.session_state.y_test = y_test
                
                st.success("‚úÖ Modelo entrenado exitosamente")
                
                # Validaci√≥n cruzada
                st.markdown("#### üìä Validaci√≥n Cruzada (5-Fold)")
                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Media R¬≤", f"{cv_scores.mean():.4f}")
                with col2:
                    st.metric("Desv. Est√°ndar", f"{cv_scores.std():.4f}")
                with col3:
                    st.metric("Min R¬≤", f"{cv_scores.min():.4f}")
                
                # Visualizar √°rbol
                st.markdown("#### üå≥ Visualizaci√≥n del √Årbol de Decisi√≥n")
                
                fig, ax = plt.subplots(figsize=(20, 10))
                plot_tree(model, filled=True, fontsize=8, ax=ax, 
                         feature_names=X.columns, rounded=True)
                st.pyplot(fig)


# ============== P√ÅGINA: EVALUACI√ìN ==============
elif page == "üìà Evaluaci√≥n":
    st.header("üìà Evaluaci√≥n del Modelo")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Por favor, entrene primero un modelo")
    else:
        model = st.session_state.model
        X_test = st.session_state.X_test
        y_test = st.session_state.y_test
        
        # Hacer predicciones
        y_pred = model.predict(X_test)
        
        # Calcular m√©tricas
        r2 = r2_score(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        
        # Mostrar m√©tricas
        st.subheader("üìä M√©tricas de Evaluaci√≥n")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("R¬≤ Score", f"{r2:.4f}")
        with col2:
            st.metric("RMSE", f"{rmse:.4f}")
        with col3:
            st.metric("MAE", f"{mae:.4f}")
        with col4:
            st.metric("MSE", f"{mse:.4f}")
        
        st.markdown("---")
        
        # Gr√°ficos
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üéØ Predicciones vs Valores Reales")
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.scatter(y_test, y_pred, alpha=0.6, edgecolors='k')
            
            min_val = min(y_test.min(), y_pred.min())
            max_val = max(y_test.max(), y_pred.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
            
            ax.set_xlabel('Valores Reales', fontsize=12)
            ax.set_ylabel('Predicciones', fontsize=12)
            ax.set_title('Predicciones vs Valores Reales', fontsize=14, fontweight='bold')
            ax.grid(alpha=0.3)
            st.pyplot(fig)
        
        with col2:
            st.subheader("üìä Distribuci√≥n de Residuos")
            residuals = y_test - y_pred
            
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='salmon')
            ax.axvline(x=0, color='red', linestyle='--', lw=2)
            ax.set_xlabel('Residuos', fontsize=12)
            ax.set_ylabel('Frecuencia', fontsize=12)
            ax.set_title('Distribuci√≥n de Residuos', fontsize=14, fontweight='bold')
            ax.grid(alpha=0.3)
            st.pyplot(fig)
        
        st.markdown("---")
        
        # Gr√°fico de residuos vs predicciones
        st.subheader("üìâ An√°lisis de Residuos")
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.scatter(y_pred, residuals, alpha=0.6, edgecolors='k')
        ax.axhline(y=0, color='red', linestyle='--', lw=2)
        ax.set_xlabel('Predicciones', fontsize=12)
        ax.set_ylabel('Residuos', fontsize=12)
        ax.set_title('Residuos vs Predicciones', fontsize=14, fontweight='bold')
        ax.grid(alpha=0.3)
        st.pyplot(fig)
        
        st.markdown("---")
        
        # Importancia de caracter√≠sticas
        st.subheader("üîç Importancia de Caracter√≠sticas")
        
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
            feature_names = st.session_state.X_test.columns
            
            feature_importance_df = pd.DataFrame({
                'Caracter√≠stica': feature_names,
                'Importancia': importances
            }).sort_values('Importancia', ascending=False).head(15)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.barh(feature_importance_df['Caracter√≠stica'], feature_importance_df['Importancia'])
            ax.set_xlabel('Importancia', fontsize=12)
            ax.set_title('Top 15 Caracter√≠sticas M√°s Importantes', fontsize=14, fontweight='bold')
            ax.invert_yaxis()
            ax.grid(alpha=0.3)
            st.pyplot(fig)
            
            with st.expander("üìã Ver tabla de importancias"):
                st.dataframe(feature_importance_df)
        
        st.markdown("---")
        
        # An√°lisis de errores
        st.subheader("‚ö†Ô∏è An√°lisis de Errores")
        
        errors = np.abs(residuals)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Error M√≠nimo", f"{errors.min():.4f}")
        with col2:
            st.metric("Error Promedio", f"{errors.mean():.4f}")
        with col3:
            st.metric("Error M√°ximo", f"{errors.max():.4f}")
        
        # Descargar reporte
        st.markdown("---")
        st.subheader("üì• Descargar Reporte")
        
        report = f"""
REPORTE DE EVALUACI√ìN DEL MODELO
================================

M√âTRICAS DE RENDIMIENTO:
- R¬≤ Score: {r2:.4f}
- RMSE: {rmse:.4f}
- MAE: {mae:.4f}
- MSE: {mse:.4f}

AN√ÅLISIS DE ERRORES:
- Error M√≠nimo: {errors.min():.4f}
- Error Promedio: {errors.mean():.4f}
- Error M√°ximo: {errors.max():.4f}
- Percentil 95: {np.percentile(errors, 95):.4f}

INFORMACI√ìN DEL DATASET:
- Tama√±o del conjunto de prueba: {len(y_test)}
- N√∫mero de caracter√≠sticas: {st.session_state.X_test.shape[1]}
"""
        
        st.download_button(
            label="üìÑ Descargar Reporte TXT",
            data=report,
            file_name="reporte_evaluacion.txt",
            mime="text/plain"
        )
        
        # Guardar modelo
        if st.button("üíæ Guardar Modelo"):
            buffer = BytesIO()
            joblib.dump(model, buffer)
            buffer.seek(0)
            
            st.download_button(
                label="üì¶ Descargar Modelo (.pkl)",
                data=buffer,
                file_name="modelo_cart.pkl",
                mime="application/octet-stream"
            )


# ============== P√ÅGINA: PREDICCIONES ==============
elif page == "üéØ Predicciones":
    st.header("üéØ Realizar Predicciones")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Por favor, entrene primero un modelo")
    else:
        model = st.session_state.model
        X_sample = st.session_state.X_test
        
        st.markdown("""
        En esta secci√≥n puede realizar predicciones con el modelo entrenado.
        Puede elegir entre:
        - Hacer una predicci√≥n individual ingresando valores manualmente
        - Hacer predicciones en lote cargando un archivo CSV
        - Ver una predicci√≥n de ejemplo aleatorio
        """)
        
        st.markdown("---")
        
        prediction_type = st.radio(
            "Seleccione el tipo de predicci√≥n:",
            ["üé≤ Predicci√≥n Individual", "üìä Predicciones en Lote", "üîÄ Ejemplo Aleatorio"]
        )
        
        # ===== PREDICCI√ìN INDIVIDUAL =====
        if prediction_type == "üé≤ Predicci√≥n Individual":
            st.subheader("Ingrese los valores de las caracter√≠sticas:")
            
            feature_values = {}
            
            # Crear inputs din√°micos para cada caracter√≠stica
            cols = st.columns(3)
            for idx, feature in enumerate(X_sample.columns):
                with cols[idx % 3]:
                    # Obtener rango de valores de la caracter√≠stica
                    min_val = float(X_sample[feature].min())
                    max_val = float(X_sample[feature].max())
                    mean_val = float(X_sample[feature].mean())
                    
                    feature_values[feature] = st.number_input(
                        f"{feature}",
                        min_value=min_val,
                        max_value=max_val,
                        value=mean_val,
                        help=f"Rango: [{min_val:.2f}, {max_val:.2f}]"
                    )
            
            if st.button("üöÄ Predecir", type="primary"):
                # Crear DataFrame con los valores
                input_df = pd.DataFrame([feature_values])
                
                # Hacer predicci√≥n
                prediction = model.predict(input_df)[0]
                
                # Mostrar resultado
                st.markdown("---")
                st.markdown("### üéØ Resultado de la Predicci√≥n")
                
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.markdown(f"""
                    <div style='text-align: center; padding: 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    border-radius: 15px; color: white;'>
                        <h2 style='margin: 0; font-size: 3rem;'>{prediction:.2f}</h2>
                        <p style='margin: 10px 0 0 0; font-size: 1.2rem;'>Rendimiento Predicho</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Mostrar valores ingresados
                with st.expander("üìã Ver valores ingresados"):
                    st.dataframe(input_df)
        
        # ===== PREDICCIONES EN LOTE =====
        elif prediction_type == "üìä Predicciones en Lote":
            st.subheader("Cargue un archivo CSV con m√∫ltiples registros")
            
            uploaded_file = st.file_uploader(
                "Seleccione un archivo CSV",
                type=['csv'],
                help="El archivo debe contener las mismas caracter√≠sticas que el modelo entrenado"
            )
            
            if uploaded_file is not None:
                try:
                    batch_data = pd.read_csv(uploaded_file)
                    st.success(f"‚úÖ Archivo cargado: {batch_data.shape[0]} registros")
                    
                    with st.expander("üëÄ Vista previa de los datos"):
                        st.dataframe(batch_data.head())
                    
                    if st.button("üöÄ Realizar Predicciones", type="primary"):
                        # Verificar que tenga las columnas correctas
                        missing_cols = set(X_sample.columns) - set(batch_data.columns)
                        
                        if missing_cols:
                            st.error(f"‚ùå Faltan las siguientes columnas: {missing_cols}")
                        else:
                            # Hacer predicciones
                            predictions = model.predict(batch_data[X_sample.columns])
                            
                            # Agregar predicciones al DataFrame
                            results_df = batch_data.copy()
                            results_df['Predicci√≥n'] = predictions
                            
                            st.success(f"‚úÖ {len(predictions)} predicciones realizadas")
                            
                            # Mostrar resultados
                            st.dataframe(results_df)
                            
                            # Estad√≠sticas de las predicciones
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Media", f"{predictions.mean():.2f}")
                            with col2:
                                st.metric("Mediana", f"{np.median(predictions):.2f}")
                            with col3:
                                st.metric("M√≠nimo", f"{predictions.min():.2f}")
                            with col4:
                                st.metric("M√°ximo", f"{predictions.max():.2f}")
                            
                            # Descargar resultados
                            csv = results_df.to_csv(index=False)
                            st.download_button(
                                label="üì• Descargar Resultados (CSV)",
                                data=csv,
                                file_name="predicciones_batch.csv",
                                mime="text/csv"
                            )
                            
                            # Visualizaci√≥n
                            fig, ax = plt.subplots(figsize=(10, 6))
                            ax.hist(predictions, bins=30, edgecolor='black', alpha=0.7, color='steelblue')
                            ax.set_xlabel('Valor Predicho', fontsize=12)
                            ax.set_ylabel('Frecuencia', fontsize=12)
                            ax.set_title('Distribuci√≥n de Predicciones', fontsize=14, fontweight='bold')
                            ax.grid(alpha=0.3)
                            st.pyplot(fig)
                
                except Exception as e:
                    st.error(f"‚ùå Error al procesar el archivo: {str(e)}")
        
        # ===== EJEMPLO ALEATORIO =====
        else:
            st.subheader("üîÄ Predicci√≥n con Ejemplo Aleatorio")
            
            if st.button("üé≤ Generar Ejemplo Aleatorio"):
                # Seleccionar un √≠ndice aleatorio
                random_idx = np.random.randint(0, len(X_sample))
                random_sample = X_sample.iloc[random_idx:random_idx+1]
                
                # Hacer predicci√≥n
                prediction = model.predict(random_sample)[0]
                
                # Valor real si existe
                if st.session_state.y_test is not None:
                    real_value = st.session_state.y_test.iloc[random_idx]
                    error = abs(real_value - prediction)
                    error_pct = (error / real_value) * 100
                
                # Mostrar resultado
                st.markdown("---")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### üìä Valores de Entrada")
                    st.dataframe(random_sample.T.rename(columns={random_idx: 'Valor'}))
                
                with col2:
                    st.markdown("### üéØ Resultados")
                    
                    if st.session_state.y_test is not None:
                        st.metric("Valor Real", f"{real_value:.2f}")
                        st.metric("Predicci√≥n", f"{prediction:.2f}", delta=f"{prediction - real_value:.2f}")
                        st.metric("Error Absoluto", f"{error:.2f}")
                        st.metric("Error Porcentual", f"{error_pct:.2f}%")
                    else:
                        st.metric("Predicci√≥n", f"{prediction:.2f}")
                
                # Gr√°fico comparativo
                if st.session_state.y_test is not None:
                    fig, ax = plt.subplots(figsize=(8, 5))
                    categories = ['Valor Real', 'Predicci√≥n']
                    values = [real_value, prediction]
                    colors = ['#2ecc71', '#3498db']
                    
                    bars = ax.bar(categories, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
                    ax.set_ylabel('Valor', fontsize=12)
                    ax.set_title('Comparaci√≥n: Real vs Predicci√≥n', fontsize=14, fontweight='bold')
                    ax.grid(axis='y', alpha=0.3)
                    
                    # A√±adir valores sobre las barras
                    for bar in bars:
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height,
                               f'{height:.2f}',
                               ha='center', va='bottom', fontsize=12, fontweight='bold')
                    
                    st.pyplot(fig)


# ============== FOOTER ==============
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #888; padding: 20px;'>
    <p>üéì Proyecto de Machine Learning Supervisado | √Årboles de Regresi√≥n CART</p>
    <p>Desarrollado con Python, Scikit-learn y Streamlit</p>
</div>
""", unsafe_allow_html=True)